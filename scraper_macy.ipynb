{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from retrying import retry\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@retry(stop_max_attempt_number=3, wait_fixed=1000)\n",
    "def extract_product_info(product_id, api_key):\n",
    "    payload = {\n",
    "        'api_key': api_key,\n",
    "        'url': f'https://www.macys.com/shop/product?ID={product_id}',\n",
    "        'country_code': 'us',\n",
    "        'device_type': 'desktop',\n",
    "        'session_number': '1'\n",
    "    }\n",
    "    r = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    selectors = {\n",
    "        'brand': ('label', {'itemprop': 'brand'}, 'a'),\n",
    "        'product_title': ('span', {'itemprop': 'name'}),\n",
    "        'offer': ('div', {'class': 'flex-container price-type-container label'}, 'span'),\n",
    "        'price': ('span', {'class': 'price-lg'}),\n",
    "        'old_price': ('span', {'class': 'price-strike-lg'}),\n",
    "        'colors': ('input', {'class': 'color-swatch-sprite-radio'}),\n",
    "        'sizes': ('li', {'class': 'shrink cell'}, 'span'),\n",
    "        'product_details': ('ul', {'class': 'margin-left-xs'}, 'li'),\n",
    "        'shipping_returns_info': ('li', {'data-auto': 'shipping-returns-section'}, ('li', {'data-testid': 'note'})),\n",
    "        'materials_and_care_info': ('li', {'data-auto': 'materials-care-section'}, 'span'),\n",
    "        'size_and_fit_info': ('li', {'data-auto': 'size-fit-section'}, 'span'),\n",
    "        'complete_the_look': None,\n",
    "        'chatbot': 'chatbot present',\n",
    "        'featured_brands': ['Donna Karan New York', 'Calvin Klein', 'Karl Lagerfeld Paris', 'Levi\\'s',\n",
    "                            'DKNY', 'Tommy Hilfiger', 'Kenneth Cole', 'Dockers', 'Champion',\n",
    "                            'Michael Kors', 'Vince Camuto', 'Anne Klein']\n",
    "    }\n",
    "\n",
    "    output = {}\n",
    "    for key, selector in selectors.items():\n",
    "        try:\n",
    "            if key == 'colors':\n",
    "                output[key] = [tag['aria-label'].replace('Color: ', '').strip() for tag in soup.find_all(*selector)]\n",
    "            elif key == 'sizes':\n",
    "                output[key] = [tag.get_text(strip=True) for tag in soup.find_all(*selector[:2])]\n",
    "            elif key == 'product_details':\n",
    "                output[key] = ', '.join([tag.get_text(strip=True) for tag in soup.find_all(*selector)])\n",
    "            elif key == 'shipping_returns_info':\n",
    "                output[key] = [tag.get_text(strip=True) for tag in soup.find(*selector[:2]).find_all(*selector[2])] \\\n",
    "                    if soup.find(*selector[:2]) else None\n",
    "            elif key == 'materials_and_care_info':\n",
    "                output[key] = [tag.get_text(strip=True) for tag in soup.find(*selector[:2]).find_all(selector[2])] \\\n",
    "                    if soup.find(*selector[:2]) else None\n",
    "            elif key == 'size_and_fit_info':\n",
    "                output[key] = [tag.get_text(strip=True) for tag in soup.find(*selector[:2]).find_all(selector[2])] \\\n",
    "                    if soup.find(*selector[:2]) else None\n",
    "            elif key == 'featured_brands':\n",
    "                output[key] = random.sample(selector, random.randint(1, len(selector)))\n",
    "            elif selector:\n",
    "                output[key] = soup.find(*selector[:2]).get_text(strip=True) if soup.find(*selector[:2]) else None\n",
    "            else:\n",
    "                output[key] = selector\n",
    "        except AttributeError:\n",
    "            output[key] = None\n",
    "\n",
    "    output['colors'] = ', '.join(output['colors']) if output['colors'] else None\n",
    "    output['sizes'] = ', '.join(output['sizes']) if output['sizes'] else None\n",
    "\n",
    "    return output\n",
    "\n",
    "def extract_product_ids(url, api_key):\n",
    "    payload = {\n",
    "        'api_key': api_key,\n",
    "        'url': url,\n",
    "        'country_code': 'us',\n",
    "        'device_type': 'desktop',\n",
    "        'session_number': '1'\n",
    "    }\n",
    "    r = requests.get('https://api.scraperapi.com/', params=payload)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "    script_tag = soup.find('script', string=lambda x: x and 'window.__INITIAL_STATE__' in x)\n",
    "    if script_tag:\n",
    "        script_text = script_tag.string if script_tag else \"\"\n",
    "        match = re.search(r'\"productID\":\\[(.*?)\\]', script_text)\n",
    "        if match:\n",
    "            product_ids_str = '[' + match.group(1) + ']'\n",
    "            product_ids = json.loads(product_ids_str)\n",
    "            return [int(pid) for pid in product_ids]\n",
    "        else:\n",
    "            logger.warning(\"No productID array found.\")\n",
    "            return []\n",
    "    else:\n",
    "        logger.warning(\"Script tag with 'window.__INITIAL_STATE__' not found.\")\n",
    "        return []\n",
    "\n",
    "def main(api_key, input_file, output_file, categories_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    df = df[df['Shipping Returns Info'].isna() | (df['Shipping Returns Info'] == '[]')]\n",
    "\n",
    "    product_ids = []\n",
    "    if categories_file:\n",
    "        with open(categories_file, 'r') as f:\n",
    "            categories = [line.strip() for line in f]\n",
    "        for url in categories:\n",
    "            product_ids.extend(extract_product_ids(url, api_key))\n",
    "\n",
    "    file_exists = False\n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8'):\n",
    "            file_exists = True\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\"PRODUCT ID\"])\n",
    "        for product_id in product_ids:\n",
    "            writer.writerow([product_id])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            product_id = row['ProductId']\n",
    "            product_info = extract_product_info(product_id, api_key)\n",
    "            for key, value in product_info.items():\n",
    "                df.at[index, key] = value\n",
    "            logger.info(f\"Updated product ID: {product_id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error updating product ID {product_id}: {e}\")\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "    logger.info(f\"CSV update completed for rows with blank or empty Shipping Returns Info.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Scrape product information from Macy\\'s website.')\n",
    "    parser.add_argument('--api-key', required=True, help='API key for Scraper API')\n",
    "    parser.add_argument('--input-file', default='20241023_Macys-ALL-BRANDS.csv', help='Input CSV file')\n",
    "    parser.add_argument('--output-file', default='20241023_Macys-ALL-BRANDS-updated.csv', help='Output CSV file')\n",
    "    parser.add_argument('--categories-file', help='Text file containing category URLs')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.api_key, args.input_file, args.output_file, args.categories_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
